---
title: "Geostatistics"
author: "Alexander J Ohrt, Mikel, Victor (add apellidos and order alphabetically) "
date: '`r format(Sys.Date(),"%e %B, %Y")`'
output: pdf_document
params:
  showCode: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = params$showCode, comment = "#>", warning = FALSE, message = FALSE)
```

This is the first assignment in Spatial Epidemiology at UPC, fall 2021. It is in the topic of Geostatistics. Don't know if we should write anything else in this "intro". 

## Load libraries and data

```{r}
library(geoR)
library(sm)
library(gstat)

coordinates <- read.table("poly84.txt", head = TRUE, sep = "\t", dec = ".")
elevs <- read.table("elevationsIslet.txt", head = TRUE, sep = "\t", dec = ".") 
head(elevs)
```


## 1. Exploration of the large scale variability of the elevation

In this problem we will explore the large scale variability of the elevation data. 

```{r}
geoelevs <- as.geodata(elevs)
summary(geoelevs)  
plot(geoelevs) 

# Remember that: 
###   (circles) : 1st quartile
###   (triangles) : 2nd quartile
###   (plus)  : 3rd quartile
###   (crosses)  : 4th quartile
```

The histogram of the elevations shows that the data is nicely distributed, resembling a normal distribution, which means that we will not need to apply a transformation at this stage. Moreover, the plot in the upper left corner shows that most of the larger values are in the upper left part of the islet, based on the red crosses, which make up the largest 25\% of values in the data set. In general, the first quartile in the data is more widespread on the islet, while the rest of the data is mostly spread out around the border of the islet. Note that the plot in the lower left shows a trend in the latitude, perhaps following a second order polynomial (upside down U). There are also some indications of a rising trend in the longitude, based on the plot in the upper right corner. An attempt at removing these trends will be done later, using a linear model. 

The plots below further ground the initial theories about the trends in the latitude and longitude. 

```{r}
with(geoelevs, plot(coords[, 1], data, xlab = "W-E",
              ylab = "Elevation data", pch = 20, cex = 0.7))
lines(with(geoelevs, lowess(data ~ coords[, 1])))

with(geoelevs, plot(coords[, 2], data, xlab = "S-N",
              ylab = "Elevation data", pch = 20, cex = 0.7))
lines(with(geoelevs, lowess(data ~ coords[, 2])))
```

Attempting to remove the trends with a linear model. The residuals of the linear regression are added to a new dataframe, with the original data.

```{r}
lm.fit <- lm(data ~ y + poly(x,2), data = elevs)
summary(lm.fit)
# lm.fit <- lm(data ~ poly(y,2) + poly(x,2), data = elevs)
# summary(lm.fit)

# Add residuals to a new data frame. 
elevs2 <- data.frame(elevs, residuals = lm.fit$residuals)
geoelevs2 <- as.geodata(elevs2, data.col = 4)
```


```{r}
plot(geoelevs2)
with(geoelevs2, plot(coords[, 1], data, xlab = "W-E",
                  ylab = "Elevation data", pch = 20, cex = 0.7))
lines(with(geoelevs2, lowess(data ~ coords[, 1])))

with(geoelevs2, plot(coords[, 2], data, xlab = "S-N",
                  ylab = "Elevation data", pch = 20, cex = 0.7))
lines(with(geoelevs2, lowess(data ~ coords[, 2])))
```

It looks like some of the trend has been removed, i.e. the linear model has explained some of the variations in the data. Note that we also attempted different combinations of dropping the second order term in latitude and adding a second order term in longitude, but found that this model gives the best results, i.e. the linear model we have used above is the simplest model that explains the data to approximately the same extent as the most complicated model (among these combinations) and the residuals have the least amount of trend. Note that this is by no means a rigorous analysis applying the linear model, but we have chosen the simplest model that qualitatively seems to remove some of the trend in the data. Therefore, we will use the residuals from the linear regression in the rest of the analysis. \textcolor{red}{What do you think about which of the linear models above we should use? The one with poly(x,2) and poly(y,2) has larger adjusted R-squared, but I think the plots look nicer with the one I have chosen here. Thoughts?}

## 2. Exploration of the small scale variability of the elevation

In this problem we will explore the small scale variability of the elevation data. 

First we calculate and plot the variogram cloud together with the empirical variogram. Remember that we now are analyzing the residuals after the linear regression presented earlier. Note that the robust estimator (`modulus`, Hawkins and Cressie 1993) is used when estimating the empirical variogram. 

```{r, results = "hide"}
# Practical rules: lags only up to half of maxdist. That is why maxdist is saved here. 
maxdist <- max(dist(cbind(elevs$x,elevs$y))) 
cloud <- variog(geoelevs2, option = "cloud", estimator.type = "modulus")
bp <- variog(geoelevs2, option = "bin", bin.cloud = T,
               pairs.min=30, max.dist=maxdist/2,
               estimator.type = "modulus") # Not sure about all these arguments. 
bin <- variog(geoelevs2, option = "bin", pairs.min=30, max.dist=maxdist/2,
                estimator.type = "modulus")
# Also: pairs,min = 30 since the sample variogram should only be considered for lags 
# that have more than 30 pairs. 

par(mfrow=c(1,3))
plot(cloud,main="CLOUD", cex.main=1, cex.lab=1, cex=2)
plot(bp, bin.cloud=T, cex.lab=1)
title(main = "BINNED BOXPLOTS", cex.main=1)
plot(bin, main="EMPIRICAL VARIOGRAMS \nBINNED",cex.main=1, cex.lab=1, cex=2, pch=16)
```

From these variogram plots it looks like the range of a variogram is approx. 30 (distance), the sill around 150 (semivariance) and the nugget might be around 30. Thus, one might say that there is spatial correlation, at least in a range of 30.

\textcolor{red}{Not sure if this should be done in this problem or in problem 3. What do you think?}
Will calculate directional variograms to study isotropic/anistropic properties also.

```{r, results = "hide"}
par(mfrow=c(1, 1))
variod <- variog4(geoelevs2,max.dist=maxdist/2, pairs.min=30,estimator.type = "modulus")
plot(variod,lyt=2,legend=FALSE)
legend(x="bottomright", inset=0.01, lty=c(1,2,3,4), col=c("black", "red", "green","blue"),
       legend=c("0º", "45º", "90º","135º"), cex=0.5)
```

We think the data looks relatively isotropic, as all 4 directions checked look relatively similar to each other. 


## 3. Exploration of the spatial independence

In this problem we will further explore the spatial independence of the process. As specified in the problem description, we will set the seed to 1000. 

```{r, results = "hide"}
set.seed(1000)
par(mfrow=c(1,1))
indep.env <- variog.mc.env(geoelevs2, coords=geoelevs2$coords, data=geoelevs2$data, obj.variog=bp, nsim=200)
plot(bp, envelope = indep.env, main="CONFIDENCE BANDS FOR INDEPENDENT MODEL", lwd=2, pch=16)
```

The confidence bands show a range of estimated variograms when the measurements are randomly permuted in the spatial points. The lower confidence band is the minimum value of the variogram for the simulated data in each point and, similarly, the upper confidence band is the maximum value. In order for the hypothesis that the process is independent, i.e. that the apparent increase in the estimated variogram with distance (from earlier) might be attributed to chance, the entire variogram should fall inside these confidence bands.
It is not clear what to conclude based on this plot only, but two points are outside the confidence bands, which indicates
that complete spatial randomness in the underlying process may be unplausible.

We will also add a Rose diagram, to study the anisotropy further. The Rose diagram will be plotted used the code supplied in the lectures (`RoseDiagram.R`).

```{r, results = "hide"}
source("../Chapter3/RoseDiagram.R") # This has to point at the RoseDiagram-file on your computer. 
rose.diagram(data.var=geoelevs2$data,data.cds=geoelevs2$coord,max.dist=maxdist/2,numcases=10,numdirec=4,poly.tnd="cte",crit.val=5)
```

The idea behind this plot is that one can see if the data looks anisotropic. If this is the case, one can try to apply a anisotropic
coordinate correction (rotational transformation) and then make the same plot as above again
(with the estimated variogram in four different directions),
to see if the data looks more isotropic. 

\textcolor{red}{This is done in "exploreSmallScaleDep.R", at the bottom of the file. Done in "study_isotropy.R" also.}

\textcolor{red}{Not sure why I do not get any output now. Does it work on your computer?}
From the Rose Diagram plotted above, it looks like the Anisotropy angle is 0 (angle between y-axis and the direction with the maximum range). Moreover, it looks like the Anisotropy ratio is 2 (ratio between maximum and minimum ranges). Thus we can try the rotational transformation below and observe if it looks more isotropic \textcolor{red}{Even though it looked pretty good to begin with IMO. What do you think?}.

```{r, results = "hide"}
angle <- 0 # No rotation in this case, only "squishing".
ratio <- 2   
elevs2.ani <- cbind(coords.aniso(geoelevs2$coords, c(angle,ratio),reverse = FALSE),geoelevs2$data)
geoelevs2.ani <- as.geodata(elevs2.ani)
plot(geoelevs2.ani)
par(mfrow=c(1,1))
variod.ani <- variog4(geoelevs2.ani, max.dist=maxdist/2, pairs.min=30,estimator.type = "modulus");
plot(variod.ani,lyt=2,legend=FALSE,main="Anisotropy angle=0,ratio=2")
legend(x="bottomright", inset=0.01, lty=c(1,2,3,4), col=c("black", "red", "green","blue"),
       legend=c("0\u00B0", "45\u00B0", "90\u00B0","135\u00B0"), cex=0.5)
```

\textcolor{red}{These variograms look about the same as earlier IMO. This tranformation-process only makes sense for geometric anisotropies?}

Making the same plots as earlier, to see if the process looks more isotropic. 

```{r, results = "hide"}
maxdist2 <- max(dist(cbind(elevs2.ani[,1],elevs2.ani[,2]))) # Practical rules: lags only up to half of maxdist. That is why this is saved here. 
cloud2 <- variog(geoelevs2.ani, option = "cloud", estimator.type = "modulus")
bp2 <- variog(geoelevs2.ani, option = "bin", bin.cloud = T,
             pairs.min=30, max.dist=maxdist2/2,
             estimator.type = "modulus") # Not sure about all these arguments. 
bin2 <- variog(geoelevs2.ani, option = "bin", pairs.min=30, max.dist=maxdist2/2,
              estimator.type = "modulus")
# Also: pairs.min = 30 since the sample variogram should only be considered for lags that have more than 30 pairs. 

par(mfrow=c(1,3))
plot(cloud2,main="CLOUD", cex.main=1, cex.lab=1, cex=2)
plot(bp2, bin.cloud=T, cex.lab=1)
title(main = "BINNED BOXPLOTS", cex.main=1)
plot(bin2, main="EMPIRICAL VARIOGRAM \nBINNED",cex.main=1, cex.lab=1, cex=2, pch=16)
```

Below we compare the sample variograms before and after the transformation. 

```{r}
par(mfrow=c(1,2))
plot(bin, main="EMPIRICAL VARIOGRAMS \nBINNED Before",cex.main=1, cex.lab=1, cex=2, pch=16)
plot(bin2, main="EMPIRICAL VARIOGRAMS \nBINNED Transf",cex.main=1, cex.lab=1, cex=2, pch=16)
```

It looks like the sills are different. \textcolor{red}{Do we have to conclude on whether this is a geometric, zonal or combined anisotropy?}

## 4. Theoretical variograms and estimations of their parameters

In this problem we will propose four theoretical variograms and estimate them via restricted maximum likelihood (REML) \textcolor{red}{Only applicable to processes with second-order stationary errors?}. Later we will select the two variograms that best fit the data and explain the parameters of the chosen variogram. We propose the exponential, Gaussian, spherical and Matérn models. Note that this is done with 'bin' for now, which is the empirical variogram estimate with the un-transformed data (referring to the transformation done above). \textcolor{red}{This can easily be changed by swapping 'bin' for 'bin2' or 'geoelevs2' for 'geoelevs2.ani'. Which data set do you think should be used here?} In order to find the initial values for optimization of the restricted maximum likelihoods, we used the function below, which is a graphical tool. 

```{r, eval = F}
eyefit(bin, silent = FALSE)
```

From this tool, we arrived at the initial values inserted into the functions below. \textcolor{red}{Please check that you also agree with these values :)}

In the functions `likfit` below, the first initial value is for the partial sill and the second initial value is for the range. We have used the default trend of `cte` in `likfit`. \textcolor{red}{What do you think about this?}

```{r, results = "hide"}
#Fit an exponential model with nugget effect.
lk1 <- likfit(geoelevs2, cov.model = "exponential", ini =c(3,0.19),
              fix.nugget = F, nugget =0.18 ,lik.method = "REML")

# Fit a Gaussian model. 
lk2 <- likfit(geoelevs2, cov.model = "gaussian", ini = c(3,0.19),
              fix.nugget = F, nugget =0.09 ,lik.method = "REML")

# Fit a spherical model with nugget effect. 
lk3 <- likfit(geoelevs2, cov.model = "spherical", ini = c(1.29,0.41),
              fix.nugget = F, nugget =0.41,lik.method = "REML")

# Fit a Matérn model. 
lk4 <- likfit(geoelevs2, cov.model = "matern", ini = c(2.03,0.41),
              fix.nugget = F, nugget =0.19, fix.kappa = FALSE, kappa=0.95,lik.method = "REML") 
# Kappa is the smoothing parameter for the Matérn model. 

# Increase number of bins to estimate the variograms (as done in 'variogramaEstimationScallops3.R')?
# This estimates a new sample variogram I think. Should this be done earlier, in problem 2/3 already perhaps?
```

The parametric variograms are plotted together with the empirical variogram below. LOOKS LIKE SHIT WITH THE MAXIMUM LIKELIHOOD. 

```{r}
par(mfrow=c(1, 1))
plot(bin,  main = "PARAMETRIC VARIOGRAMS",cex.main = 1, pch = 16)
lines(lk1, lwd = 2, col = "red", max.dist = maxdist/2)
lines(lk2, lwd = 2, col = "blue", max.dist = maxdist/2)
lines(lk3, lwd = 2, col = "green3", max.dist = maxdist/2)
lines(lk4, lwd = 2, col = "yellow", max.dist = maxdist/2)
legend(x = "bottomright", inset = 0.01, lty = c(1, 1), col = c("red", "blue", "green3","yellow"),
       legend = c("Exponential", "Gaussian", "Spherical","Matérn"), cex = 1)
```

I AM TRYING WITH LEAST SQUARES AS WELL: comment on what Cressie is. 

```{r, results = "hide"}
# Exponential variogram. 
wls1 <- variofit(bin, cov.model = "exponential", ini = c(3,0.19),
                 fix.nugget = F, nugget =0.18 , weights="cressie")

# Gaussian variogram.
wls2 <- variofit(bin, cov.model = "gaussian", ini = c(3,0.19),
                 fix.nugget = F, nugget =0.09, weights="cressie")

# Spherical. 
wls3 <- variofit(bin, cov.model = "spherical", ini = c(1.29,0.41),
                 fix.nugget = F, nugget =0.4, weights="cressie")

# Matérn variogram.
wls4 <- variofit(bin, cov.model = "matern", ini = c(2,0.4),
                 fix.nugget = F, nugget =0.2, fix.kappa = FALSE, kappa=0.95,weights="cressie")
```

```{r}
par(mfrow=c(1, 1))
plot(bin,  main = "PARAMETRIC VARIOGRAMS",cex.main = 1, pch = 16)
lines(wls1, lwd = 2, col = "red", max.dist = maxdist/2)
lines(wls2, lwd = 2, col = "blue", max.dist = maxdist/2)
lines(wls3, lwd = 2, col = "green3", max.dist = maxdist/2)
lines(wls4, lwd = 2, col = "yellow", max.dist = maxdist/2)
legend(x = "bottomright", inset = 0.01, lty = c(1, 1), col = c("red", "blue", "green3","yellow"),
       legend = c("Exponential", "Gaussian", "Spherical","Matérn"), cex = 1)
```

THE LEAST SQUARED LOOKS WAY BETTER, HENCE WILL CONTINUE WORKING WITH THOSE FOR NOW. MAYBE NEED TO USE BIN2 ?

Selecting the variograms that best fit the data can be done by a combination of inspecting the semivariance plot (qualitative), comparing the sum of squares from the minimizations and comparing the AIC \textcolor{red}{AIC only seems to exist for maximum likelihood}. From inspection it looks like the Exponential and the Matérn are the two best models. The quantiative measures are summarized in the table below. 

```{r}
comparison <- data.frame("Model" = c("Exponential", "Gaussian", "Spherical","Matérn"),
                "Sum of Squares" = c(summary(wls1)$sum.of.squares, summary(wls2)$sum.of.squares,
                    summary(wls3)$sum.of.squares, summary(wls4)$sum.of.squares), 
                        "AIC" = c(0,0,0,0))
knitr::kable(comparison)
```

From the table we can see that the visual insights are further substantiated by the sum of squares. Hence, we choose the Exponential and Matérn models. Now, let us explain the parameters from the models. First of all, the parameters are the following

```{r}
# looks like the maximum likelihood also gives a lot more parameters ?
# Maybe we should use the max likelihood if we can get it to work properly!
wls1$nugget
wls4$nugget
```


In general the parameters of the variogram represent the following quantities:

* Nugget: The nugget effect presents micro-scale variation or measurement error. This can be seen graphically as the $y$-value where the variogram crosses the $y$-axis.

* Sill: The sill represents the variance of the random field. Note that a quantity called the *partial sill* is defined as $\sigma^2=\text{sill} - \text{nugget}$.

* Range: The range represents the distance at which the data no longer are autocorrelated. This can be seen graphically by noting the distance, i.e. the $x$-value, where the variogram stops increasing or becomes approximately parallell to the $x$-axis. 

Now, how about the parameters of the chosen variograms? 

## 5. Predictions of elevations along the area of study

In this final problem we will use kriging to predict elevations along the area of study. This will be done using the two best variaograms among the four proposed theoretical variograms in problem 4. 

```{r}
# Make grid for kriging and do it. 
```

# General questions to profe: 
* Should we somehow comment on if the random process is Stationary, Weak Stationary or Intrinsic Stationary?
